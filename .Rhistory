gsub('$', '',abnb$price)
gsub("$"," ", abnb$price)
abnb
gsub("$", " ", abnb$price)
gsub('[^[:alnum:] ]','',abnb$price)
abnb$price <- gsub('[^[:alnum:] ]','',abnb$price)
abnb
as.numeric(abnb$price)
abnb$price <- as.numeric(abnb$price)
glimpse(abnb)
abnb$`service fee` <- gsub('[^[:alnum:] ]','',abnb$`service fee`)
abnb$`service fee` <- as.numeric(abnb$`service fee`)
glimpse(abnb)
library(tidyverse)
library(readr)
library(stringr)
abnb <- read_csv("Development/Projects/doTERRA Assessment/Airbnb_Open_Data.csv")
abnb <- as_tibble(abnb)
abnb <- abnb %>%
select(NAME, `host id`, host_identity_verified, `neighbourhood group`,
neighbourhood, `room type`, `Construction year`, price, `service fee`)
abnb <- na.omit(abnb)
table(abnb['room type'])
table(abnb['neighbourhood group'])
abnb %>%
count(`room type`)
abnb %>%
count(`neighbourhood group`)
# Omit the misspelled 'brookln' neighbourhood group
abnb <- abnb[abnb$`neighbourhood group` != 'brookln', ]
abnb %>%
count(`neighbourhood group`)
# Only view the verified host id's
abnb <- abnb %>%
filter(host_identity_verified == 'verified')
# Remove the $ and , from price and service fee, then convert to numeric
abnb$price <- gsub('[^[:alnum:] ]','',abnb$price)
abnb$price <- as.numeric(abnb$price)
abnb$`service fee` <- gsub('[^[:alnum:] ]','',abnb$`service fee`)
abnb$`service fee` <- as.numeric(abnb$`service fee`)
glimpse(abnb)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(avg_price = mean(price))
abnb %>%
count(`neighbourhood group`)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(avg_price = mean(price))
abnb %>%
group_by(`neighbourhood group`) %>%
aggregate(price)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price))
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = mean(pricex))
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = mean(price))
abnb
abnb %>%
filter(`neighbourhood group` == 'Bronx')
bronx <- abnb %>%
filter(`neighbourhood group` == 'Bronx')
mean(bronx$price)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = mean(round(price)))
mean(bronx$price)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = round(mean(price)),2)
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = round(mean(price),2))
abnb %>%
group_by(`neighbourhood group`) %>%
summarize(max_price = max(price),
mean_price = mean(price))
library(tidyverse)
library(rvest)
url <- https://www.espn.com/nba/player/stats/_/id/3908845/john-collins
url <- 'https://www.espn.com/nba/player/stats/_/id/3908845/john-collins'
library(tidyverse)
library(vroom)
library(patchwork)
library(tidymodels)
library(poissonreg)
bike <- vroom("./train.csv")
bike <- vroom("./train.csv")
bike <- bike %>%
select(-casual, -registered)
pen_preds <- predict(preg_wf, new_data = test) %>% #This predicts log(count)
mutate(.pred=exp(.pred)) %>% # Back-transform the log to original scale
bind_cols(., test) %>% #Bind predictions with test data
select(datetime, .pred) %>% #Just keep datetime and predictions
rename(count=.pred) %>% #rename pred to count (for submission to Kaggle)
mutate(count=pmax(0, count)) %>% #pointwise max of (0, prediction)
mutate(datetime=as.character(format(datetime))) #needed for right format to Kaggle
library(tidyverse)
library(vroom)
library(patchwork)
library(tidymodels)
library(poissonreg)
bike <- vroom("./train.csv")
colnames(predictions) <- c('datetime', 'count')
# Change formatting of datetime
predictions$datetime <- as.character(predictions$datetime)
# Write that dataset to a csv file
vroom_write(predictions, 'predictions.csv', ",")
library(tidyverse)
library(vroom)
library(patchwork)
library(tidymodels)
library(poissonreg)
bike <- vroom("./train.csv")
bike <- bike %>%
select(-casual, -registered)
## Bike Share Clean Code
library(tidyverse)
library(vroom)
library(patchwork)
library(tidymodels)
library(poissonreg)
bike <- vroom("./train.csv")
bike <- bike %>%
select(-casual, -registered)
install.packages('embed')
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed)
train <- vroom("./train.csv")
train <- vroom("./train.csv")
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
abnb <- abnb %>%
select(id, host_id, host_id, host_name, host_identity_verified, neighbourhood_group, neighbourhood, lat, long, room_type,
Construction_year, price) %>%
filter(host_identity_verified == 'verified')
# Transform the price column and convert Construction_year to factor
abnb <- abnb %>%
mutate(price = str_replace_all(price, "\\$", "") %>%    # Replace dollar signs
str_replace_all(",", "") %>%               # Replace commas
as.numeric()) %>%
mutate(Construction_year = as.factor(Construction_year))
# Transform the price column
abnb <- abnb %>%
mutate(price = str_replace_all(price, "\\$", "") %>%    # Replace dollar signs
str_replace_all(",", "") %>%               # Replace commas
as.numeric())
# Count NA's in columns
na_count <- colSums(is.na(abnb))
abnb <- abnb %>%
drop_na(neighbourhood_group, neighbourhood, lat, long)
# Check to make sure that the NA's are removed from the groups that I wanted
sum(is.na(abnb$neighbourhood_group))
sum(is.na(abnb$neighbourhood))
sum(is.na(abnb$lat))
sum(is.na(abnb$long))
unique(abnb$neighbourhood_group)
# Change misspelled values in neighbourhood_group to make sure they match the real value
abnb <- abnb %>%
mutate(neighbourhood_group = case_when(
neighbourhood_group == "brookln" ~ "Brooklyn",
neighbourhood_group == "manhatan" ~ "Manhattan",
TRUE ~ neighbourhood_group # This makes sure that other values are unchanged
))
unique(abnb$neighbourhood_group)
vroom_write(abnb, ".\abnb.csv", delim = ",")
view(abnb)
library(readr)
Nascar_Loop_Data <- read_csv("Development/Projects/Nascar Loop Data.csv")
View(Nascar_Loop_Data)
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
problems()
view(abnb)
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
# Convert house_rules to lowercase
abnb$house_rules <- tolower(abnb$house_rules)
# Count listings that mention allowing pets
pets_allowed <- sum(str_detect(abnb$house_rules, "pets allowed"))
# Count listings that mention not allowing pets
no_pets <- sum(str_detect(abnb$house_rules, "no pets"))
cat("Number of listings that allow pets:", pets_allowed, "\n")
cat("Number of listings that do not allow pets:", no_pets, "\n")
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
# Convert house_rules to lowercase
abnb$house_rules <- tolower(abnb$house_rules)
# Count listings that mention allowing pets
pets_allowed <- sum(str_detect(abnb$house_rules, "pets"))
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
# Convert house_rules to lowercase
abnb$house_rules <- tolower(abnb$house_rules)
# Count listings that mention allowing pets
pets_allowed <- sum(str_detect(abnb$house_rules, "pets"))
pets_allowed
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
# Filter rows where 'house_rules' mentions 'pets'
pets <- abnb %>%
filter(str_detect(house_rules, "pet"))
# View the filtered data
head(pets)
view(pets)
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
# Filter rows where 'house_rules' mentions 'pets'
pets <- abnb %>%
filter(str_detect(house_rules, "no pets"))
# View the filtered data
head(pets)
# Filter rows where 'house_rules' mentions 'pets'
no_pets <- abnb %>%
filter(str_detect(house_rules, "no pets"))
view(no_pets)
install.packages('doParallel')
library(readr)
nfl_suspensions_data <- read_csv("Downloads/nfl-suspensions-data.csv")
View(nfl_suspensions_data)
library(tidvyerse)
nfl_suspensions <- read_csv("Downloads/nfl-suspensions-data.csv")
suspensions_per_year <- nfl_suspensions %>%
group_by(year) %>%
summarise(count = n())
print(suspensions_per_year)
getwd()
library(tidvyerse)
library(tidvyerse)
install.packages('tidyverser')
install.packages('tidyverse')
install.packages("tidyverse")
library(tidvyerse)
library(tidyverse)
library(vroom)
library(readr)
library(stringr)
abnb <- read_csv("/Users/tylersmith/Development/Projects/doterra/Airbnb_Open_Data.csv")
# Replace spaces with underscores in column names
names(abnb) <- gsub(" ", "_", names(abnb))
abnb <- abnb %>%
select(id, host_id, host_id, host_name, host_identity_verified, neighbourhood_group, neighbourhood, lat, long, room_type,
Construction_year, price) %>%
filter(host_identity_verified == 'verified')
# Transform the price column and convert Construction_year to factor
abnb <- abnb %>%
mutate(price = str_replace_all(price, "\\$", "") %>%    # Replace dollar signs
str_replace_all(",", "") %>%               # Replace commas
as.numeric()) %>%
mutate(Construction_year = as.factor(Construction_year))
# Transform the price column
abnb <- abnb %>%
mutate(price = str_replace_all(price, "\\$", "") %>%    # Replace dollar signs
str_replace_all(",", "") %>%               # Replace commas
as.numeric())
# Count NA's in columns
na_count <- colSums(is.na(abnb))
abnb <- abnb %>%
drop_na(neighbourhood_group, neighbourhood, lat, long)
# Check to make sure that the NA's are removed from the groups that I wanted
sum(is.na(abnb$neighbourhood_group))
sum(is.na(abnb$neighbourhood))
sum(is.na(abnb$lat))
sum(is.na(abnb$long))
unique(abnb$neighbourhood_group)
# Change misspelled values in neighbourhood_group to make sure they match the real value
abnb <- abnb %>%
mutate(neighbourhood_group = case_when(
neighbourhood_group == "brookln" ~ "Brooklyn",
neighbourhood_group == "manhatan" ~ "Manhattan",
TRUE ~ neighbourhood_group # This makes sure that other values are unchanged
))
unique(abnb$neighbourhood_group)
view(abnb)
view(abnb)
view(abnb2)
library(readr)
nfl_suspensions_data <- read_csv("Development/Projects/nfl-suspensions-data.csv")
View(nfl_suspensions_data)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
nfl_suspensions
nfl_suspensions %>%
filter(year == 2012)
library(tidyverse)
nfl_suspensions %>%
filter(year == 2012)
view(nfl_suspensions %>%
filter(year == 2012))
len(nfl_suspensions %>%
filter(year == 2012))
filter(year == 2012))
length(nfl_suspensions %>%
filter(year == 2012))
nfl_suspensions %>%
filter(year == 2012)
library(readr)
nfl_suspensions_data <- read_csv("Development/Projects/nfl-suspensions-data.csv")
View(nfl_suspensions_data)
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
view(nfl_suspensions)
all_years <- tibble(Year = 1986:2014)
nfl_data_complete <- all_years %>%
left_join(nfl_data, by = "Year") %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
nfl_data_complete <- all_years %>%
left_join(nfl_suspensions, by = "Year") %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
nfl_data_complete <- all_years %>%
left_join(nfl_suspensions, by = "year") %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(Year = 1986:2015)
nfl_data_complete <- all_years %>%
left_join(nfl_suspensions, by = c("Year" = "Year")) %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(Year = 1986:2015)
nfl_data_complete <- all_years %>%
left_join(nfl_suspensions, by = c("year" = "year")) %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(year = 1986:2015)
nfl_data_complete <- all_years %>%
left_join(nfl_suspensions, by = c("year" = "year")) %>%
mutate(Suspensions = ifelse(is.na(Suspensions), 0, Suspensions))
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(Year = 1986:2015)
nfl_suspensions_2 <- all_years %>%
left_join(nfl_suspensions, by = "year") %>%
group_by(year) %>%
summarize(suspensions_count = n())
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(year = 1986:2015)
nfl_suspensions_2 <- all_years %>%
left_join(nfl_suspensions, by = "Year") %>%
group_by(year) %>%
summarize(suspensions_count = n())
library(tidyverse)
nfl_suspensions <- read_csv("Development/Projects/nfl-suspensions-data.csv")
all_years <- tibble(year = 1986:2015)
nfl_suspensions_2 <- all_years %>%
left_join(nfl_suspensions, by = "year") %>%
group_by(year) %>%
summarize(suspensions_count = n())
write.csv(nfl_suspensions_2, "nfl_supsensions_2.csv", row.names = FALSE)
view(nfl_suspensions_2)
nfl_suspensions_updated <- nfl_suspensions %>%
left_join(nfl_suspensions_2, by = "year")
view(nfl_suspensions_updated)
view(nfl_data_updated)
nfl_data_updated <- nfl_data %>%
full_join(nfl_suspensions_2, by = "year")
nfl_suspensions_updated <- nfl_suspensions %>%
full_join(nfl_suspensions_2, by = "year")
nfl_suspensions_updated$games[is.na(nfl_suspensions_updated$games)] <- 0
unique(nfl_suspensions_updated$Year)
unique(nfl_suspensions_updated$year)
head(gg)
head(ggg)
train <- vroom("./train.csv")
#################################
# ggg Analysis
#################################
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed) # for target encoding
library(ranger)
library(rpart)
library(discrim)
library(naivebayes)
library(kknn)
library(doParallel)
library(themis)
library(stacks)
train <- vroom("./train.csv")
setwd("~/Desktop/STAT348/ggg")
train <- vroom("./train.csv")
train <- vroom("./train.csv")
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed) # for target encoding
library(ranger)
library(rpart)
library(discrim)
library(naivebayes)
library(kknn)
library(doParallel)
library(themis)
library(stacks)
train <- vroom("./train.csv")
test <- vroom("./test.csv")
train_na <- vroom("./trainWithMissingValues")
view(train_na)
train_na <- vroom("./trainWithMissingValues")
getwd()
#################################
# ggg Analysis
#################################
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed) # for target encoding
library(ranger)
library(rpart)
library(discrim)
library(naivebayes)
library(kknn)
library(doParallel)
library(themis)
library(stacks)
train <- vroom("./train.csv")
test <- vroom("./test.csv")
train_na <- vroom("./trainWithMissingValues")
train_na <- vroom("./trainWithMissingValues.")
train_na <- vroom("./trainWithMissingValues.csv")
view(train_na)
columns_with_na <- names(train_na)[which(colSums(is.na(train_na)) > 0)]
print(columns_with_na)
view(train_na)
na_recipe <- recipe(type ~, train_na) %>%
na_recipe <- recipe(type ~., train_na) %>%
step_impute(bone_length, rotting_flesh, hair_length)
na_recipe <- recipe(type ~., train_na) %>%
step_impute_mean(bone_length, rotting_flesh, hair_length)
baked <- bake(prepped_na_recipe, new_data = na_recipe)
prepped_na_recipe <- prep(my_recipe)
prepped_na_recipe <- prep(train_na_recipe)
prepped_na_recipe <- prep(na_recipe)
baked <- bake(na_recipe, new_data = train_na)
baked
#################################
# ggg Analysis
#################################
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed) # for target encoding
library(ranger)
library(rpart)
library(discrim)
library(naivebayes)
library(kknn)
library(doParallel)
library(themis)
library(stacks)
train <- vroom("./train.csv")
test <- vroom("./test.csv")
train_na <- vroom("./trainWithMissingValues.csv")
columns_with_na <- names(train_na)[which(colSums(is.na(train_na)) > 0)]
print(columns_with_na)
na_recipe <- recipe(type ~., train_na) %>%
step_impute_mean(bone_length, rotting_flesh, hair_length)
prepped_na_recipe <- prep(na_recipe)
baked <- bake(na_recipe, new_data = train_na)
baked <- bake(prepped_na_recipe, new_data = train_na)
baked
rmse_vec(trainSet[is.na(train_na)], imputedSet[is.na(train_na)])
rmse_vec(train[is.na(train_na)], baked[is.na(train_na)])
